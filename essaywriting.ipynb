{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an essay. \\\n",
    "Write such an outline for the user provided topic. Give an outline of the essay along with any relevant notes \\\n",
    "or instructions for the sections.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following essay. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 5-paragraph essays.\\\n",
    "Generate the best essay possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize all the information below as needed: \n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "import os\n",
    "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 1 plan node\n",
    "def plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT), \n",
    "        HumanMessage(content=state['task'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"plan\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agent 2: Research plan node\n",
    "def research_plan_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_node(state: AgentState):\n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\")\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=WRITER_PROMPT.format(content=content)\n",
    "        ),\n",
    "        user_message\n",
    "        ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response.content, \n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT), \n",
    "        HumanMessage(content=state['draft'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"critique\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_critique_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "        HumanMessage(content=state['critique'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x115ce5d60>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x115ce5d60>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.set_entry_point(\"planner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x115ce5d60>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    should_continue,\n",
    "    {\n",
    "        END: END, \"reflect\": \"reflect\"\n",
    "    }\n",
    ")\n",
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'planner': {'plan': 'I. Introduction\\n    A. Brief overview of Langchain and Langsmith\\n    B. Thesis statement: Exploring the differences between Langchain and Langsmith\\n\\nII. Langchain\\n    A. Definition and explanation\\n    B. Key features and characteristics\\n    C. Use cases and applications\\n    D. Advantages and disadvantages\\n\\nIII. Langsmith\\n    A. Definition and explanation\\n    B. Key features and characteristics\\n    C. Use cases and applications\\n    D. Advantages and disadvantages\\n\\nIV. Comparison between Langchain and Langsmith\\n    A. Technical differences\\n    B. Functional differences\\n    C. Market adoption and popularity\\n    D. Future prospects and trends\\n\\nV. Conclusion\\n    A. Recap of main points\\n    B. Final thoughts on the significance of understanding the differences between Langchain and Langsmith'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/purva.samdani/langgraph/.venv/lib/python3.9/site-packages/langchain_openai/chat_models/base.py:1844: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n",
      "/Users/purva.samdani/langgraph/.venv/lib/python3.9/site-packages/langchain_openai/chat_models/base.py:1857: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'research_plan': {'content': ['LangChain vs LangSmith: Understanding the Differences, Pros, and Cons | by Ajay Verma | GoPenAI LangChain and LangSmith are two powerful tools developed by LangChain, a company focused on making it easier to build and deploy Large Language Model (LLM) applications. In this blog, we‚Äôll delve into the differences between LangChain and LangSmith, their pros and cons, and when to use each one. Comprehensive Platform: LangSmith offers a unified platform for managing all aspects of LLM development, making it ideal for large-scale, production-ready applications. LangChain and LangSmith are two complementary tools that cater to different stages and requirements of LLM development. LangChain is ideal for early-stage prototyping and small-scale applications, while LangSmith is better suited for large-scale, production-ready applications that require advanced debugging, testing, and monitoring capabilities.', 'If you‚Äôre responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. If you‚Äôre debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith‚Äôs advanced debugging and orchestration features** will be indispensable. Additionally, if you‚Äôre working on **cross-platform model deployments** ‚Äî say, running models on-prem and in the cloud simultaneously ‚Äî Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'LangChain allows AI developers to develop applications based on the combined Large Language Models (such as GPT-4) with external sources of computation and data. Vector database plays a key role in tasks like document retrieval, knowledge base integration, or context-based search, providing the model with dynamic, real-time data to enhance responses. LangChain follows a structured pipeline that integrates user queries, data retrieval and response generation into seamless workflow. Import LangChain and initialize the OpenAI LLM (Large Language Model) using the `OpenAI` class: It involves managing the data flow between the program and the file system on the storage device, ensuring that data is handled safely a 7 min readArtificial Neural Networks and its Applications Artificial Neural Networks (ANNs) are computer systems designed to mimic how the human brain processes information.', \"*   Build a simple LLM application with chat models and prompt templates *   How to migrate from legacy LangChain agents to LangGraph *   How to use chat models to call tools *   How to pass tool outputs to chat models *   **`langchain`**: Chains, agents, and retrieval strategies that make up an application's cognitive architecture. However, these guides will help you quickly accomplish common tasks using chat models, vector stores, and other common LangChain components. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. If you're looking to get up and running quickly with chat models, vector stores, or other LangChain components from a specific provider, check out our growing list of integrations.\", 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith # Get started with LangSmith **LangSmith** is a platform for building production-grade LLM applications. LangSmith + LangChain OSS For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph. LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith‚Äôs observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production. The LangSmith SDK and UI make building and running high-quality evaluations easy. - Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.', 'LangSmith Performance cookies are used to understand and analyze the key performance indexes of the website which helps in delivering a better user experience for the visitors. LangSmith is a unified observability & evals platform where teams can debug, test, and monitor AI app performance ‚Äî whether building with LangChain or not. Evaluate your app by saving production traces to datasets ‚Äî then score performance with LLM-as-Judge evaluators. LangSmith traces contain the full information of all the inputs and outputs of each step of the application, giving users full visibility into their agent or LLM app behavior. LangSmith also allows users to instantly run evals to assess agent or LLM app performance ‚Äî including LLM-as-Judge evaluators for auto-scoring and the ability to attach human feedback.']}}\n",
      "{'generate': {'draft': \"**Title: LangChain vs LangSmith: Understanding the Differences, Pros, and Cons**\\n\\nI. **Introduction**\\nLangChain and LangSmith are two powerful tools developed by LangChain, a company focused on making it easier to build and deploy Large Language Model (LLM) applications. This essay will delve into the differences between LangChain and LangSmith, providing insights into their unique features, use cases, advantages, and disadvantages.\\n\\nII. **LangChain**\\nLangChain is designed for early-stage prototyping and small-scale applications. It allows developers to integrate Large Language Models (LLMs) like GPT-4 with external computation sources, enhancing responses with real-time data. The structured pipeline of LangChain seamlessly manages user queries, data retrieval, and response generation. While it excels in managing and scaling model workflows, it may lack the advanced debugging and monitoring capabilities required for large-scale production-ready applications.\\n\\nIII. **LangSmith**\\nIn contrast, LangSmith offers a unified platform for managing all aspects of LLM development, making it ideal for large-scale, production-ready applications. It provides advanced debugging, testing, and monitoring capabilities, catering to the needs of developers working on complex AI systems in production. LangSmith's observability features ensure meaningful insights throughout all stages of application development.\\n\\nIV. **Comparison between LangChain and LangSmith**\\n- **Technical Differences:** LangChain focuses on early-stage prototyping and integration with external data sources, while LangSmith is tailored for large-scale, production-ready applications with advanced debugging features.\\n- **Functional Differences:** LangChain is suitable for managing and scaling model workflows, while LangSmith excels in providing deep visibility and control over complex AI systems in production.\\n- **Market Adoption and Popularity:** LangSmith's observability features and advanced debugging capabilities have made it a preferred choice for developers working on production-grade LLM applications.\\n- **Future Prospects and Trends:** As AI applications continue to evolve, both LangChain and LangSmith are expected to adapt and enhance their features to meet the changing demands of the industry.\\n\\nV. **Conclusion**\\nUnderstanding the differences between LangChain and LangSmith is crucial for developers and organizations looking to build and deploy LLM applications. While LangChain caters to early-stage prototyping and small-scale applications, LangSmith is better suited for large-scale, production-ready applications with advanced debugging and monitoring capabilities. By choosing the right tool based on specific requirements, developers can optimize their workflow and enhance the performance of their AI applications.\", 'revision_number': 2}}\n",
      "{'reflect': {'critique': '**Critique:**\\n\\n1. **Introduction:**\\n   - The introduction provides a clear overview of the topic but could be enhanced by including a brief background on the importance of Large Language Models (LLMs) in the current technological landscape.\\n\\n2. **LangChain and LangSmith Descriptions:**\\n   - The descriptions of LangChain and LangSmith are informative and provide a good understanding of their respective functionalities. However, more specific examples or case studies could be included to illustrate their applications in real-world scenarios.\\n\\n3. **Comparison Section:**\\n   - The comparison between LangChain and LangSmith is well-structured and highlights key technical and functional differences. To further enrich this section, consider incorporating a detailed analysis of how these differences impact the development process and end results.\\n\\n4. **Market Adoption and Future Prospects:**\\n   - The discussion on market adoption and future prospects is insightful. To strengthen this section, you could include statistical data or references to support the claims made about the popularity and potential growth of LangSmith in the industry.\\n\\n5. **Conclusion:**\\n   - The conclusion effectively summarizes the key points discussed in the essay. To enhance it, consider adding a call to action or a recommendation for developers on how to choose between LangChain and LangSmith based on their specific project requirements.\\n\\n**Recommendations:**\\n\\n1. **Depth and Detail:**\\n   - Provide more in-depth analysis by including specific examples, case studies, or user experiences to illustrate the practical applications and benefits of LangChain and LangSmith.\\n\\n2. **Length and Expansion:**\\n   - Consider expanding on each section to provide a more comprehensive overview of the differences, pros, and cons of LangChain and LangSmith. This will help readers gain a deeper understanding of the topic.\\n\\n3. **Style and Tone:**\\n   - Maintain a formal and professional tone throughout the essay. Ensure consistency in terminology and avoid overly technical language that may be difficult for non-experts to understand.\\n\\n4. **References and Citations:**\\n   - Include references to support any claims or data presented in the essay. This will add credibility to your analysis and provide readers with additional resources for further exploration.\\n\\n5. **Visual Aids:**\\n   - Incorporate visual aids such as charts, graphs, or diagrams to visually represent the differences between LangChain and LangSmith. This can help readers grasp complex information more easily.\\n\\nBy implementing these recommendations, you can enhance the clarity, depth, and overall quality of your essay on LangChain vs LangSmith.'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/purva.samdani/langgraph/.venv/lib/python3.9/site-packages/langchain_openai/chat_models/base.py:1844: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n",
      "/Users/purva.samdani/langgraph/.venv/lib/python3.9/site-packages/langchain_openai/chat_models/base.py:1857: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'research_critique': {'content': ['LangChain vs LangSmith: Understanding the Differences, Pros, and Cons | by Ajay Verma | GoPenAI LangChain and LangSmith are two powerful tools developed by LangChain, a company focused on making it easier to build and deploy Large Language Model (LLM) applications. In this blog, we‚Äôll delve into the differences between LangChain and LangSmith, their pros and cons, and when to use each one. Comprehensive Platform: LangSmith offers a unified platform for managing all aspects of LLM development, making it ideal for large-scale, production-ready applications. LangChain and LangSmith are two complementary tools that cater to different stages and requirements of LLM development. LangChain is ideal for early-stage prototyping and small-scale applications, while LangSmith is better suited for large-scale, production-ready applications that require advanced debugging, testing, and monitoring capabilities.', 'If you‚Äôre responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. If you‚Äôre debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith‚Äôs advanced debugging and orchestration features** will be indispensable. Additionally, if you‚Äôre working on **cross-platform model deployments** ‚Äî say, running models on-prem and in the cloud simultaneously ‚Äî Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'LangChain allows AI developers to develop applications based on the combined Large Language Models (such as GPT-4) with external sources of computation and data. Vector database plays a key role in tasks like document retrieval, knowledge base integration, or context-based search, providing the model with dynamic, real-time data to enhance responses. LangChain follows a structured pipeline that integrates user queries, data retrieval and response generation into seamless workflow. Import LangChain and initialize the OpenAI LLM (Large Language Model) using the `OpenAI` class: It involves managing the data flow between the program and the file system on the storage device, ensuring that data is handled safely a 7 min readArtificial Neural Networks and its Applications Artificial Neural Networks (ANNs) are computer systems designed to mimic how the human brain processes information.', \"*   Build a simple LLM application with chat models and prompt templates *   How to migrate from legacy LangChain agents to LangGraph *   How to use chat models to call tools *   How to pass tool outputs to chat models *   **`langchain`**: Chains, agents, and retrieval strategies that make up an application's cognitive architecture. However, these guides will help you quickly accomplish common tasks using chat models, vector stores, and other common LangChain components. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. If you're looking to get up and running quickly with chat models, vector stores, or other LangChain components from a specific provider, check out our growing list of integrations.\", 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith # Get started with LangSmith **LangSmith** is a platform for building production-grade LLM applications. LangSmith + LangChain OSS For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph. LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith‚Äôs observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production. The LangSmith SDK and UI make building and running high-quality evaluations easy. - Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.', 'LangSmith Performance cookies are used to understand and analyze the key performance indexes of the website which helps in delivering a better user experience for the visitors. LangSmith is a unified observability & evals platform where teams can debug, test, and monitor AI app performance ‚Äî whether building with LangChain or not. Evaluate your app by saving production traces to datasets ‚Äî then score performance with LLM-as-Judge evaluators. LangSmith traces contain the full information of all the inputs and outputs of each step of the application, giving users full visibility into their agent or LLM app behavior. LangSmith also allows users to instantly run evals to assess agent or LLM app performance ‚Äî including LLM-as-Judge evaluators for auto-scoring and the ability to attach human feedback.', 'Large language models (LLMs) are a category of foundation models trained on immense amounts of data making them capable of understanding and generating natural language and other types of content to perform a wide range of tasks. LLMs are a class of foundation models, which are trained on enormous amounts of data to provide the foundational capabilities needed to drive multiple use cases and applications, as well as resolve a multitude of tasks. IBM watsonx is powered by the latest AI models to intelligently process conversations and provide help whenever and wherever you may need it. IBM watsonx is powered by the latest AI models to intelligently process conversations and provide help whenever and wherever you may need it.', 'Large Language Models are required to fully reflect the complex, domain-specific needs of the manufacturing industry.', 'If you‚Äôre responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. If you‚Äôre debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith‚Äôs advanced debugging and orchestration features** will be indispensable. Additionally, if you‚Äôre working on **cross-platform model deployments** ‚Äî say, running models on-prem and in the cloud simultaneously ‚Äî Langsmith offers better orchestration and monitoring tools to handle the complexity.', \"LangSmith steps in to give you the tools you need to debug and monitor your models at scale, ensuring everything is running as expected in your AI system. You might think of LangSmith as LangChain's counterpart, but it takes things further by focusing on managing, debugging, and orchestrating AI and ML models. LangSmith steps in to give you the tools you need to debug and monitor your models at scale, ensuring everything is running as expected in your AI system. In short, while LangChain excels at managing and scaling model workflows, LangSmith is designed for when you need deep visibility and control over large, complex AI systems in production. If you're debugging complex AI models or managing large-scale workflows with multiple moving parts, LangSmith's advanced debugging and orchestration features will be indispensable.\", 'Image 11: First, what even is an agent? ### First, what even is an agent? agents in production? The top use cases for agents include **performing research and summarization (58%)**, followed by streamlining tasks for **personal productivity or assistance (53.5%). Customer service (45.8%) is another prime area for agent use cases, helping companies handle inquiries, troubleshoot, and speed up customer response times across teams. Agent controls by company size Image 19: Agent controls by company size While rates of agent adoption were similar across non-tech and tech company respondents, among those using agent controls in production, tech companies were more likely to use multiple control methods.**51% of tech respondents are currently using 2 or more control methods**, compared to only **39% of respondents in other sectors**.', 'The average percentage of traces involving tool calls has seen a dramatic increase, jumping from 0.5% in 2023 to 21.9% in 2024. This staggering']}}\n",
      "{'generate': {'draft': \"**Title: LangChain vs LangSmith: Understanding the Differences, Pros, and Cons**\\n\\nI. **Introduction**\\nLangChain and LangSmith are two powerful tools developed by LangChain, a company focused on making it easier to build and deploy Large Language Model (LLM) applications. This essay will delve into the differences between LangChain and LangSmith, providing insights into their unique features and applications.\\n\\nII. **LangChain**\\nLangChain is designed for early-stage prototyping and small-scale applications. It allows developers to integrate Large Language Models (LLMs) with external computation sources, enhancing responses with real-time data. Key features include structured pipelines for seamless workflow integration. While advantageous for managing and scaling model workflows, LangChain may lack the advanced debugging and monitoring capabilities required for large-scale production-ready applications.\\n\\nIII. **LangSmith**\\nIn contrast, LangSmith is tailored for large-scale, production-ready applications that demand advanced debugging, testing, and monitoring features. It offers LLM-native observability, enabling meaningful insights throughout all stages of application development. LangSmith's performance cookies and evaluators provide a unified platform for debugging, testing, and monitoring AI applications, whether built with LangChain or not.\\n\\nIV. **Comparison between LangChain and LangSmith**\\n- **Technical Differences:** LangChain focuses on early-stage prototyping and workflow management, while LangSmith emphasizes advanced debugging and monitoring for production-grade applications.\\n- **Functional Differences:** LangChain integrates LLMs with external data sources, while LangSmith offers observability features and performance evaluation tools.\\n- **Market Adoption:** LangChain caters to small-scale applications, while LangSmith targets large-scale production applications, influencing their respective market adoption.\\n- **Future Prospects:** The future trends suggest a continued need for both tools, with LangChain supporting prototyping needs and LangSmith enhancing production application monitoring.\\n\\nV. **Conclusion**\\nUnderstanding the distinctions between LangChain and LangSmith is crucial for developers and organizations aiming to leverage LLM applications effectively. While LangChain excels in managing workflows, LangSmith provides advanced debugging and monitoring capabilities for large-scale applications, ensuring optimal performance and reliability in AI systems.\", 'revision_number': 3}}\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for s in graph.stream({\n",
    "    'task': \"what is the difference between langchain and langsmith\",\n",
    "    \"max_revisions\": 2,\n",
    "    \"revision_number\": 1,\n",
    "    \"plan\": \"\",\n",
    "    \"draft\": \"\",\n",
    "    \"critique\": \"\",\n",
    "    \"content\": []\n",
    "}, thread):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
